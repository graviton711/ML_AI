{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc56fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[1 1 4]\n",
      " [7 9 1]\n",
      " [3 3 6]]\n",
      "Matrix B:\n",
      "[[16 14 11]\n",
      " [14 11 18]\n",
      " [16 15 17]]\n",
      "Transpose of A:\n",
      "[[1 7 3]\n",
      " [1 9 3]\n",
      " [4 1 6]]\n",
      "Transpose of A using transpose():\n",
      "[[1 7 3]\n",
      " [1 9 3]\n",
      " [4 1 6]]\n",
      "Sum of two matrices A and B:\n",
      "[[17 15 15]\n",
      " [21 20 19]\n",
      " [19 18 23]]\n",
      "Difference of two matrices A and B:\n",
      "[[-15 -13  -7]\n",
      " [ -7  -2 -17]\n",
      " [-13 -12 -11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.random.randint(1, 10, size=(3, 3))\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "\n",
    "B = np.random.randint(10, 20, size=(3, 3))\n",
    "\n",
    "print(\"Matrix B:\")\n",
    "print(B)\n",
    "\n",
    "A_T = A.T\n",
    "print(\"Transpose of A:\")\n",
    "print(A_T)\n",
    "A_T = A.transpose()\n",
    "print(\"Transpose of A using transpose():\")\n",
    "print(A_T)\n",
    "\n",
    "C = A + B\n",
    "print(\"Sum of two matrices A and B:\")\n",
    "print(C)\n",
    "D = A - B\n",
    "print(\"Difference of two matrices A and B:\")\n",
    "print(D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e355ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector 1:\n",
      "[8 3 7 8 2]\n",
      "vector 2:\n",
      "[10 12 14 19 15]\n",
      "Dot product of v1 and v2:\n",
      "396\n"
     ]
    }
   ],
   "source": [
    "#Note book 31/10/2025\n",
    "#Dot product of two vectors\n",
    "import numpy as np\n",
    "\n",
    "v1 = np.random.randint(1, 10, size=5)\n",
    "v2 = np.random.randint(10, 20, size=5)\n",
    "\n",
    "print(\"Vector 1:\")\n",
    "print(v1)\n",
    "\n",
    "print(\"vector 2:\")\n",
    "print(v2)\n",
    "\n",
    "dot_product = np.dot(v1, v2)\n",
    "print(\"Dot product of v1 and v2:\")\n",
    "print(dot_product)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "827e7916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random vector with  10  dimensions: \n",
      "[21 36 52 63 90 99 51 77 73 10]\n",
      "L2_Norm of the given vector:  200.67386476569388\n"
     ]
    }
   ],
   "source": [
    "#Notebook 31/10/2025\n",
    "#Time: 8:23PM\n",
    "#L2 Norm function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "n = 10\n",
    "\n",
    "v1 = np.random.randint(10, 100, size=(n))\n",
    "\n",
    "print(\"Random vector with \", n, \" dimensions: \")\n",
    "print(v1)\n",
    "\n",
    "L2_Norm = 0\n",
    "for vi in v1:\n",
    "    L2_Norm+=vi**2\n",
    "\n",
    "L2_Norm = math.sqrt(L2_Norm)\n",
    "\n",
    "print(\"L2_Norm of the given vector: \", L2_Norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef42fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value by column: \n",
      "[0.45878619 0.55184511 0.47315351]\n",
      "Mean subtract: \n",
      "[[-0.08323064 -0.37525247  0.3248943 ]\n",
      " [ 0.00270225  0.08847487 -0.07144125]\n",
      " [ 0.16097438 -0.44235261  0.00439172]\n",
      " [ 0.05789707  0.17024737 -0.27377902]\n",
      " [ 0.0521797   0.20358782 -0.18253425]\n",
      " [-0.35601354  0.08426303  0.18179288]\n",
      " [-0.01557506 -0.0016001   0.01576902]\n",
      " [-0.3642262   0.25536129  0.03367282]\n",
      " [ 0.01798789  0.25416556  0.41806939]\n",
      " [ 0.52730414 -0.23689476 -0.45083561]]\n",
      "Covariance matrix by numpy: \n",
      "[[ 0.06410493 -0.02917585 -0.03992678]\n",
      " [-0.02917585  0.0675313   0.0025554 ]\n",
      " [-0.03992678  0.0025554   0.07015768]]\n",
      "Covariance matrix by manual: \n",
      "[[ 0.06410493 -0.02917585 -0.03992678]\n",
      " [-0.02917585  0.0675313   0.0025554 ]\n",
      " [-0.03992678  0.0025554   0.07015768]]\n",
      "Two covariance matrix are equal:  True\n"
     ]
    }
   ],
   "source": [
    "#Notebook 1/11/2025\n",
    "#Time: 7:00AM\n",
    "#Covariance Matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cov(A):\n",
    "    N = A.shape[0]\n",
    "    mean_vector = np.mean(A, axis=0) #axis = 0 calculate mean by column\n",
    "    print(\"Mean value by column: \")\n",
    "    print(mean_vector)\n",
    "    B = A - mean_vector\n",
    "    print(\"Mean subtract: \")\n",
    "    print(B)\n",
    "\n",
    "    #@ is dot product\n",
    "    #B.T is B^T\n",
    "    covariance_matrix_manual = (B.T @ B) / (N - 1)\n",
    "    return covariance_matrix_manual\n",
    "\n",
    "A = np.random.rand(10, 3)\n",
    "#rowvar=False to calculate the covariance by column, default is by row\n",
    "covariance_matrix_numpy = np.cov(A, rowvar=False)\n",
    "covariance_matrix_manual = cov(A)\n",
    "\n",
    "print(\"Covariance matrix by numpy: \")\n",
    "print(covariance_matrix_numpy)\n",
    "print(\"Covariance matrix by manual: \")\n",
    "print(covariance_matrix_manual)\n",
    "\n",
    "\n",
    "print(\"Two covariance matrix are equal: \", np.allclose(covariance_matrix_manual, covariance_matrix_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70ad2518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix X: \n",
      "[[1.         0.47227004 0.4688179 ]\n",
      " [1.         0.29705554 0.42838573]\n",
      " [1.         0.1601545  0.38057752]\n",
      " [1.         0.63719813 0.53314133]\n",
      " [1.         0.07300282 0.59002105]\n",
      " [1.         0.78884531 0.08999095]\n",
      " [1.         0.51918533 0.53889397]\n",
      " [1.         0.99319035 0.90051107]\n",
      " [1.         0.90360736 0.59886612]\n",
      " [1.         0.2015776  0.07285194]]\n",
      "Model weights: \n",
      "[[0.61449247]\n",
      " [0.88900633]\n",
      " [0.77444083]]\n",
      "Actual label: \n",
      "[[0.64411229]\n",
      " [0.1063106 ]\n",
      " [0.18017645]\n",
      " [0.94257188]\n",
      " [0.9767826 ]\n",
      " [0.59660312]\n",
      " [0.4559789 ]\n",
      " [0.97970861]\n",
      " [0.32872639]\n",
      " [0.4593046 ]]\n",
      "MSE cost: \n",
      "0.8734553785148591\n"
     ]
    }
   ],
   "source": [
    "#Notebook 2/11/2025\n",
    "#Time: 6:43AM\n",
    "#MSE (Mean Squared Error)\n",
    "import numpy as np\n",
    "\n",
    "def compute_cost(X, w, y):\n",
    "    m = X.shape[0]\n",
    "    #residual (The distance between model's predicted label and actual label)\n",
    "    r = (X @ w - y)\n",
    "    cost = np.sum(r**2) / m\n",
    "    return cost\n",
    "\n",
    "#m samples\n",
    "#n features\n",
    "\n",
    "m = 10\n",
    "n = 2\n",
    "\n",
    "X = np.random.rand(m, n)\n",
    "\n",
    "#Add one more column for bias\n",
    "X = np.concatenate((np.ones((m, 1)), X), axis=1)\n",
    "\n",
    "print(\"Matrix X: \")\n",
    "print(X)\n",
    "\n",
    "#weights vector\n",
    "w = np.random.rand(n+1, 1)\n",
    "\n",
    "print(\"Model weights: \")\n",
    "print(w)\n",
    "\n",
    "#Actual label\n",
    "y = np.random.rand(m, 1)\n",
    "print(\"Actual label: \")\n",
    "print(y)\n",
    "\n",
    "print(\"MSE cost: \")\n",
    "print(compute_cost(X, w, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
